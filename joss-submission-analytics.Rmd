---
title: "JOSS submission analytics"
date: "`r Sys.time()`"
output: 
  html_document:
    code_folding: hide
    theme: sandstone
    highlight: tango
    toc: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, dev = c("png", "pdf"))
```

# Introduction

In this report, we extract information about published JOSS papers and generate  graphics as well as a summary table that can be downloaded and used for further analyses. 

# Load required R packages

```{r load-packages, class.source = 'fold-show'}
suppressPackageStartupMessages({
  library(tibble)
  library(rcrossref)
  library(dplyr)
  library(tidyr)
  library(ggplot2)
  library(lubridate)
  library(gh)
  library(purrr)
  library(jsonlite)
  library(DT)
  library(plotly)
})
```

```{r source-track, class.source = 'fold-hide'}
## Keep track of the source of each column
source_track <- c()
```

# Collect information about papers

## Pull down papers and citation info from Crossref

We get the information about published JOSS papers from Crossref, using the `rcrossref` R package. This package is also used to extract citation counts.

```{r pull-crossref, class.source = 'fold-show'}
## Fetch JOSS papers from Crossref
## Only 1000 papers at the time can be pulled down
lim <- 1000
papers <- rcrossref::cr_works(filter = c(issn = "2475-9066"), 
                              limit = lim)$data
i <- 1
while (nrow(papers) == i * lim) {
  papers <- dplyr::bind_rows(
    papers, 
    rcrossref::cr_works(filter = c(issn = "2475-9066"), 
                        limit = lim, offset = i * lim)$data)
  i <- i + 1
}
papers <- papers %>%
  dplyr::filter(type == "journal-article") 

## A few papers don't have DOIs - generate them from the URL
noaltid <- which(is.na(papers$alternative.id))
papers$alternative.id[noaltid] <- gsub("http://dx.doi.org/", "",
                                       papers$url[noaltid])

## Get citation info from Crossref and merge with paper details
cit <- rcrossref::cr_citation_count(doi = papers$alternative.id)
papers <- papers %>% dplyr::left_join(
  cit %>% dplyr::rename(citation_count = count), 
  by = c("alternative.id" = "doi")
)

## Remove one duplicated paper
papers <- papers %>% dplyr::filter(alternative.id != "10.21105/joss.00688")

source_track <- c(source_track, 
                  structure(rep("crossref", ncol(papers)), 
                            names = colnames(papers)))
```

## Pull down info from Whedon API

For each published paper, we use the Whedon API to get information about pre-review and review issue numbers, corresponding software repository etc.

```{r pull-whedon, class.source = 'fold-show'}
whedon <- list()
p <- 1
a <- jsonlite::fromJSON(
  url(paste0("https://joss.theoj.org/papers/published.json?page=", p)),
  simplifyDataFrame = FALSE
)
while (length(a) > 0) {
  whedon <- c(whedon, a)
  p <- p + 1
  a <- jsonlite::fromJSON(
    url(paste0("https://joss.theoj.org/papers/published.json?page=", p)),
    simplifyDataFrame = FALSE
  )
}

whedon <- do.call(dplyr::bind_rows, lapply(whedon, function(w) {
  data.frame(api_title = w$title, 
             api_state = w$state,
             repo_url = w$repository_url,
             review_issue_id = w$review_issue_id,
             doi = w$doi,
             prereview_issue_id = ifelse(!is.null(w$meta_review_issue_id),
                                         w$meta_review_issue_id, NA_integer_),
             languages = paste(w$metadata$paper$languages, collapse = ","),
             archive_doi = w$metadata$paper$archive_doi)
}))

papers <- papers %>% dplyr::left_join(whedon, by = c("alternative.id" = "doi"))

source_track <- c(source_track, 
                  structure(rep("whedon", length(setdiff(colnames(papers),
                                                         names(source_track)))), 
                            names = setdiff(colnames(papers), names(source_track))))
```

## Combine with info from GitHub issues

From each pre-review and review issue, we extract information about review times and assigned labels. 

```{r pull-github, class.source = 'fold-show', message = FALSE}
## Pull down info on all issues in the joss-reviews repository
issues <- gh("/repos/openjournals/joss-reviews/issues", 
             .limit = 5000, state = "all")
```

```{r extract-github, class.source = 'fold-show'}
## From each issue, extract required information
iss <- do.call(dplyr::bind_rows, lapply(issues, function(i) {
  data.frame(title = i$title, 
             number = i$number,
             state = i$state,
             opened = i$created_at,
             closed = ifelse(!is.null(i$closed_at),
                             i$closed_at, NA_character_),
             ncomments = i$comments,
             labels = paste(setdiff(
               vapply(i$labels, getElement, 
                      name = "name", character(1L)),
               c("review", "pre-review", "query-scope", "paused")),
               collapse = ","))
}))

## Split into REVIEW, PRE-REVIEW, and other issues (the latter category 
## is discarded)
issother <- iss %>% dplyr::filter(!grepl("\\[PRE REVIEW\\]", title) & 
                                    !grepl("\\[REVIEW\\]", title))
dim(issother)
head(issother)

## For REVIEW issues, generate the DOI of the paper from the issue number
getnbrzeros <- function(s) {
  paste(rep(0, 5 - nchar(s)), collapse = "")
}
issrev <- iss %>% dplyr::filter(grepl("\\[REVIEW\\]", title)) %>%
  dplyr::mutate(nbrzeros = purrr::map_chr(number, getnbrzeros)) %>%
  dplyr::mutate(alternative.id = paste0("10.21105/joss.", 
                                        nbrzeros,
                                        number)) %>%
  dplyr::select(-nbrzeros) %>% 
  dplyr::mutate(title = gsub("\\[REVIEW\\]: ", "", title)) %>%
  dplyr::rename_at(vars(-alternative.id), ~ paste0("review_", .))

## For PRE-REVIEW issues, add information about the corresponding REVIEW 
## issue number
isspre <- iss %>% dplyr::filter(grepl("\\[PRE REVIEW\\]", title)) %>%
  dplyr::filter(!grepl("withdrawn", labels)) %>%
  dplyr::filter(!grepl("rejected", labels))
## Some titles have multiple pre-review issues. In these cases, keep the latest
isspre <- isspre %>% dplyr::arrange(desc(number)) %>% 
  dplyr::filter(!duplicated(title)) %>% 
  dplyr::mutate(title = gsub("\\[PRE REVIEW\\]: ", "", title)) %>%
  dplyr::rename_all(~ paste0("prerev_", .))

papers <- papers %>% dplyr::left_join(issrev, by = "alternative.id") %>% 
  dplyr::left_join(isspre, by = c("prereview_issue_id" = "prerev_number")) %>%
  dplyr::mutate(prerev_opened = as.Date(prerev_opened),
                prerev_closed = as.Date(prerev_closed),
                review_opened = as.Date(review_opened),
                review_closed = as.Date(review_closed)) %>% 
  dplyr::mutate(days_in_pre = prerev_closed - prerev_opened,
                days_in_rev = review_closed - review_opened,
                to_review = !is.na(review_opened))

source_track <- c(source_track, 
                  structure(rep("joss-github", length(setdiff(colnames(papers),
                                                              names(source_track)))), 
                            names = setdiff(colnames(papers), names(source_track))))
```

## Add information from software repositories

```{r check-software-repos, class.source = 'fold-show', message = FALSE}
software_urls <- papers$repo_url
is_github <- grepl("github", software_urls)
length(is_github)
sum(is_github)
software_urls[!is_github]
```

```{r get-software-repos, class.source = 'fold-show', message = FALSE, results = 'hide', warning = FALSE}
df <- do.call(dplyr::bind_rows, lapply(software_urls[is_github], function(u) {
  u0 <- gsub("^http://", "https://", gsub("\\.git$", "", gsub("/$", "", u)))
  if (grepl("/tree/", u0)) {
    u0 <- strsplit(u0, "/tree/")[[1]][1]
  }
  if (grepl("/blob/", u0)) {
    u0 <- strsplit(u0, "/blob/")[[1]][1]
  }
  info <- try({
    gh(gsub("(https://)?(www.)?github.com/", "/repos/", u0))
  })
  contribs <- try({
    gh(paste0(gsub("(https://)?(www.)?github.com/", "/repos/", u0), "/contributors"), 
       .limit = 500)
  })
  if (!is(info, "try-error") && length(info) > 1) {
    if (!is(contribs, "try-error")) {
      if (length(contribs) == 0) {
        repo_nbr_contribs <- repo_nbr_contribs_2ormore <- NA_integer_
      } else {
        repo_nbr_contribs <- length(contribs)
        repo_nbr_contribs_2ormore <- sum(vapply(contribs, function(x) x$contributions >= 2, NA_integer_))
        if (is.na(repo_nbr_contribs_2ormore)) {
          print(contribs)
        }
      }
    } else {
      repo_nbr_contribs <- repo_nbr_contribs_2ormore <- NA_integer_
    }
    data.frame(repo_url = u, 
               repo_created = info$created_at,
               repo_updated = info$updated_at,
               repo_pushed = info$pushed_at,
               repo_nbr_stars = info$stargazers_count,
               repo_language = ifelse(!is.null(info$language),
                                      info$language, NA_character_),
               repo_license = ifelse(!is.null(info$license),
                                     info$license$key, NA_character_),
               repo_nbr_contribs = repo_nbr_contribs,
               repo_nbr_contribs_2ormore = repo_nbr_contribs_2ormore
    )
  } else {
    NULL
  }
})) %>%
  dplyr::mutate(repo_created = as.Date(repo_created),
                repo_updated = as.Date(repo_updated),
                repo_pushed = as.Date(repo_pushed)) %>%
  dplyr::distinct()
stopifnot(length(unique(df$repo_url)) == length(df$repo_url))
papers <- papers %>% dplyr::left_join(df, by = "repo_url")

source_track <- c(source_track, 
                  structure(rep("sw-github", length(setdiff(colnames(papers),
                                                            names(source_track)))), 
                            names = setdiff(colnames(papers), names(source_track))))
```

## Clean up a bit

```{r clean-up, class.source = 'fold-show'}
## Convert publication date to Date format
## Add information about the half year (H1, H2) of publication
## Count number of authors
papers <- papers %>% dplyr::select(-reference, -license, -link) %>%
  dplyr::mutate(published.date = as.Date(published.print)) %>% 
  dplyr::mutate(
    halfyear = paste0(year(published.date), 
                      ifelse(month(published.date) <= 6, "H1", "H2"))
  ) %>% dplyr::mutate(
    halfyear = factor(halfyear, 
                      levels = paste0(rep(sort(unique(year(published.date))), 
                                          each = 2), c("H1", "H2")))
  ) %>% dplyr::mutate(nbr_authors = vapply(author, function(a) nrow(a), NA_integer_))

source_track <- c(source_track, 
                  structure(rep("cleanup", length(setdiff(colnames(papers),
                                                          names(source_track)))), 
                            names = setdiff(colnames(papers), names(source_track))))
```

# Tabulate number of missing values

In some cases, fetching information from (e.g.) the GitHub API fails for a subset of the publications. There are also other reasons for missing values (for example, the earliest submissions do not have an associated pre-review issue). The table below lists the number of missing values for each of the variables in the data frame.

```{r nbr-missing, class.source = 'fold-hide'}
DT::datatable(
  data.frame(variable = colnames(papers),
             nbr_missing = colSums(is.na(papers))) %>%
    dplyr::mutate(source = source_track[variable]),
  escape = FALSE, rownames = FALSE, 
  options = list(scrollX = TRUE)
)
```


# Number of published papers per month and year

```{r papers-month, class.source = 'fold-hide', fig.width = 8, message = FALSE}
ggplot(papers %>% 
         dplyr::mutate(pubmonth = lubridate::floor_date(published.date, "month")) %>%
         dplyr::group_by(pubmonth) %>%
         dplyr::summarize(npub = n()), 
       aes(x = factor(pubmonth), y = npub)) + 
  geom_bar(stat = "identity") + theme_minimal() + 
  labs(x = "", y = "Number of published papers per month") + 
  theme(axis.title = element_text(size = 15),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```

```{r papers-year, class.source = 'fold-hide', fig.width = 8, message = FALSE}
ggplot(papers %>% 
         dplyr::mutate(pubyear = lubridate::year(published.date)) %>%
         dplyr::group_by(pubyear) %>%
         dplyr::summarize(npub = n()), 
       aes(x = factor(pubyear), y = npub)) + 
  geom_bar(stat = "identity") + theme_minimal() + 
  labs(x = "", y = "Number of published papers per year") + 
  theme(axis.title = element_text(size = 15),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```

# Citation distribution

Papers with 20 or more citations are grouped in the ">=20" category.

```{r citation-distribution, class.source = 'fold-hide'}
ggplot(papers %>% 
         dplyr::mutate(citation_count = replace(citation_count,
                                                citation_count >= 20, ">=20")) %>%
         dplyr::mutate(citation_count = factor(citation_count, 
                                               levels = c(0:20, ">=20"))) %>%
         dplyr::group_by(citation_count) %>%
         dplyr::tally(),
       aes(x = citation_count, y = n)) + 
  geom_bar(stat = "identity") + 
  theme_minimal() + 
  labs(x = "Crossref citation count", y = "Number of publications")
```


# Most cited papers

The table below sorts the JOSS papers in decreasing order by the number of citations in Crossref.

```{r most-cited, class.source = 'fold-hide'}
DT::datatable(
  papers %>% 
    dplyr::mutate(url = paste0("<a href='", url, "' target='_blank'>", 
                               url,"</a>")) %>% 
    dplyr::arrange(desc(citation_count)) %>% 
    dplyr::select(title, url, published.date, citation_count),
  escape = FALSE,
  options = list(scrollX = TRUE)
)
```

# Citation count vs time since publication

```{r citations-vs-time, class.source = 'fold-hide', message = FALSE}
plotly::ggplotly(
  ggplot(papers, aes(x = published.date, y = citation_count, label = title)) + 
    geom_point(alpha = 0.5) + theme_bw() + scale_y_sqrt() + 
    geom_smooth() + 
    labs(x = "Date of publication", y = "Crossref citation count") + 
    theme(axis.title = element_text(size = 15)),
  tooltip = c("label", "x", "y")
)
```

# Power law of citation count within each half year

Here, we plot the citation count for all papers published within each half year, sorted in decreasing order. 

```{r power-law-citations, class.source = 'fold-hide'}
ggplot(papers %>% dplyr::group_by(halfyear) %>% 
         dplyr::arrange(desc(citation_count)) %>%
         dplyr::mutate(idx = seq_along(citation_count)), 
       aes(x = idx, y = citation_count)) + 
  geom_point(alpha = 0.5) + 
  facet_wrap(~ halfyear, scales = "free") + 
  theme_bw() + 
  labs(x = "Index", y = "Crossref citation count")
```


# Pre-review/review time over time

In these plots we investigate whether the time a submission spends in the pre-review or review stage has changed over time. 

```{r review-time, class.source = 'fold-hide', message = FALSE, warning = FALSE}
ggplot(papers, aes(x = prerev_opened, y = as.numeric(days_in_pre))) + 
  geom_point() + geom_smooth() + theme_bw() + 
  scale_y_sqrt() + 
  labs(x = "Date of pre-review opening", y = "Number of days in pre-review") + 
  theme(axis.title = element_text(size = 15))

ggplot(papers, aes(x = review_opened, y = as.numeric(days_in_rev))) + 
  geom_point() + geom_smooth() + theme_bw() + 
  scale_y_sqrt() + 
  labs(x = "Date of review opening", y = "Number of days in review") + 
  theme(axis.title = element_text(size = 15))
```

# Languages

Next, we consider the languages used by the submissions. Note that a given submission can use multiple languages. 

```{r languages, class.source = 'fold-hide', fig.width = 9}
sspl <- strsplit(papers$languages, ",")
all_languages <- unique(unlist(sspl))
langs <- do.call(dplyr::bind_rows, lapply(all_languages, function(l) {
  data.frame(language = l,
             nbr_submissions = sum(vapply(sspl, function(v) l %in% v, 0)))
}))
langs %>% dplyr::arrange(desc(nbr_submissions))
ggplot(langs %>% dplyr::arrange(desc(nbr_submissions)) %>%
         dplyr::mutate(language = factor(language, levels = language)),
       aes(x = language, y = nbr_submissions)) + 
  geom_bar(stat = "identity") + 
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) + 
  labs(x = "", y = "Number of submissions") + 
  theme(axis.title = element_text(size = 15))
```

# Association between number of citations and number of stars of the GitHub repo

```{r citation-stars, class.source = 'fold-hide'}
ggplotly(
  ggplot(papers, aes(x = citation_count, y = repo_nbr_stars,
                     label = title)) + 
    geom_point(alpha = 0.5) + scale_x_sqrt() + scale_y_sqrt() + 
    theme_bw() + 
    labs(x = "Crossref citation count", y = "Number of stars, GitHub repo") + 
    theme(axis.title = element_text(size = 15)),
  tooltip = c("label", "x", "y")
)
```

# Distribution of time between GitHub repo creation and JOSS submission

```{r creation-to-submission, class.source = 'fold-hide', warning = FALSE}
ggplot(papers, aes(x = as.numeric(prerev_opened - repo_created))) +
  geom_histogram(bins = 50) + 
  theme_bw() + 
  labs(x = "Time (days) from repo creation to JOSS pre-review start") + 
  theme(axis.title = element_text(size = 15))
```

# Distribution of time between JOSS acceptance and last commit

```{r acceptance-to-commit, class.source = 'fold-hide', warning = FALSE, fig.width = 8}
ggplot(papers, aes(x = as.numeric(repo_pushed - review_closed))) +
  geom_histogram(bins = 50) + 
  theme_bw() + 
  labs(x = "Time (days) from closure of JOSS review to most recent commit in repo") + 
  theme(axis.title = element_text(size = 15)) + 
  facet_wrap(~ year(published.date), scales = "free_y")
```

# Number of authors per paper

List the papers with the largest number of authors, and display the distribution of the number of authors per paper, for papers with at most 20 authors.

```{r nbr-authors-top, class.source = 'fold-show'}
## Papers with largest number of authors
papers %>% dplyr::arrange(desc(nbr_authors)) %>% 
  dplyr::select(title, published.date, url, nbr_authors) %>%
  as.data.frame() %>% head(10)
```

```{r nbr-authors, class.source = 'fold-hide', message = FALSE}
nbins <- max(papers$nbr_authors[papers$nbr_authors <= 20])
ggplot(papers %>% dplyr::filter(nbr_authors <= 20),
  aes(x = nbr_authors)) + 
  geom_histogram(bins = nbins, fill = "lightgrey", color = "grey50") + 
  theme_bw() + 
  facet_wrap(~ year(published.date), scales = "free_y") + 
  theme(axis.title = element_text(size = 15)) + 
  labs(x = "Number of authors", y = "Number of publications with\na given number of authors")

ggplot(papers %>% 
         dplyr::mutate(nbr_authors = replace(nbr_authors, nbr_authors > 5, ">5")) %>%
         dplyr::mutate(nbr_authors = factor(nbr_authors, levels = c("1", "2", "3", 
                                                                    "4", "5", ">5"))) %>%
         dplyr::mutate(year = year(published.date)) %>%
         dplyr::mutate(year = factor(year)) %>%
         dplyr::group_by(year, nbr_authors, .drop = FALSE) %>%
         dplyr::summarize(n = n()) %>%
         dplyr::mutate(freq = n/sum(n)) %>%
         dplyr::mutate(year = as.integer(as.character(year))), 
       aes(x = year, y = freq, fill = nbr_authors)) + geom_area() + 
  theme_minimal() + 
  scale_fill_brewer(palette = "Set1", name = "Number of\nauthors", 
                    na.value = "grey") + 
  theme(axis.title = element_text(size = 15)) + 
  labs(x = "Year", y = "Fraction of submissions")

```

# Number of authors vs number of contributors to the GitHub repo

Note that points are slightly jittered to reduce the overlap. 

```{r nbr-authors-contribs, class.source = 'fold-hide', message = FALSE}
plotly::ggplotly(
  ggplot(papers, aes(x = nbr_authors, y = repo_nbr_contribs_2ormore, label = title)) + 
    geom_abline(slope = 1, intercept = 0) + 
    geom_jitter(width = 0.05, height = 0.05, alpha = 0.5) + 
    # geom_point(alpha = 0.5) + 
    theme_bw() + 
    scale_x_sqrt() + scale_y_sqrt() + 
    labs(x = "Number of authors", y = "Number of contributors\nwith at least 2 commits") + 
    theme(axis.title = element_text(size = 15)),
  tooltip = c("label", "x", "y")
)
```


# Distribution of software repo licenses

```{r repo-license, class.source = 'fold-hide', warning = FALSE, message = FALSE}
ggplot(papers, aes(x = repo_license)) +
  geom_bar() + 
  theme_bw() + 
  labs(x = "Software license", y = "Number of submissions") + 
  theme(axis.title = element_text(size = 15),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) + 
  facet_wrap(~ year(published.date), scales = "free_y")
```

```{r repl-license, class.source = 'fold-show', warning = FALSE, message = FALSE}
## For plots below, replace licenses present in less 
## than 2.5% of the submissions by 'other'
tbl <- table(papers$repo_license)
to_replace <- names(tbl[tbl <= 0.025 * nrow(papers)])
```

```{r plot-repo-license, class.source = 'fold-hide', warning = FALSE, message = FALSE}
ggplot(papers %>% 
         dplyr::mutate(year = year(published.date)) %>%
         dplyr::mutate(repo_license = replace(repo_license, 
                                              repo_license %in% to_replace,
                                              "other")) %>%
         dplyr::mutate(year = factor(year), repo_license = factor(repo_license)) %>%
         dplyr::group_by(year, repo_license, .drop = FALSE) %>%
         dplyr::count() %>%
         dplyr::mutate(year = as.integer(as.character(year))), 
       aes(x = year, y = n, fill = repo_license)) + geom_area() + 
  theme_minimal() + 
  scale_fill_brewer(palette = "Set1", name = "Software\nlicense", 
                    na.value = "grey") + 
  theme(axis.title = element_text(size = 15)) + 
  labs(x = "Year", y = "Number of submissions")

ggplot(papers %>% 
         dplyr::mutate(year = year(published.date)) %>%
         dplyr::mutate(repo_license = replace(repo_license, 
                                              repo_license %in% to_replace,
                                              "other")) %>%
         dplyr::mutate(year = factor(year), repo_license = factor(repo_license)) %>%
         dplyr::group_by(year, repo_license, .drop = FALSE) %>%
         dplyr::summarize(n = n()) %>%
         dplyr::mutate(freq = n/sum(n)) %>%
         dplyr::mutate(year = as.integer(as.character(year))), 
       aes(x = year, y = freq, fill = repo_license)) + geom_area() + 
  theme_minimal() + 
  scale_fill_brewer(palette = "Set1", name = "Software\nlicense", 
                    na.value = "grey") + 
  theme(axis.title = element_text(size = 15)) + 
  labs(x = "Year", y = "Fraction of submissions")
```


# Save object

The tibble object with all data collected above is serialized to a file that can be downloaded and reused. To read the current version of this file directly from GitHub, use the following code:

```{r, class.source = 'fold-show', eval = FALSE}
papers <- readRDS(gzcon(url("https://github.com/openjournals/joss-analytics/blob/gh-pages/joss_submission_analytics.rds?raw=true")))
```


```{r save-data}
head(papers) %>% as.data.frame()
saveRDS(papers, file = "joss_submission_analytics.rds")
```

# Session info

```{r session-info}
sessionInfo()
```

